---
title: "Chapter 5"
output: html_document
---

<!-- rmarkdown::github_document-->

#1-a)

Plugging in to the cdf of rayleigh F,
F(3)-F(1) should be the answer


```{r}
(1-exp(-9/2))-(1-exp(-1/2))
```

#1-b)

If F(x)=1/j, whats x?

or $F^-1(1/j)=?$

q1=sqrt(-2*log(1-1/4)) 

```{r}
sqrt(-2*log(1-1/4))
```

q2=sqrt(-2*log(1-2/4))

```{r}
sqrt(-2*log(1-2/4))
```

q3=sqrt(-2*log(1-3/4)) 

```{r}
sqrt(-2*log(1-3/4))
```

#2-a)

for x in (0,0.25) f(x)=2
this gives 1/2 probability mass

for x in (0.25,1) f(x)=2/3
this also gives 1/2 probability mass since (3/4)*(2/3)=0.5

#2-b)

if its bigger than 1 it will make integral>1 
which is not allowed


#3-a)
To be a valid pdf
it must be >0
and integrate to 1

since f and F are >0 g is also >0

since $F^2$ is the antiderivative of $2Ff$

$\int_{-\infty}^{+\infty}Ff/2dx$=1-0=1

#3-b)
h is positive since f(-x) and f(x) are positive.

It integrates to 1 because for the second term of the sum the integral is 1/2.

And for the first term
if we substitute -x=u then -dx=du
we get the same integral with limits reversed.

u going from 
positive infinity to negative. The answer comes out negative. But we have a minus sign from -dx

So its 1/2


#4-a)

$P(X<=x|X>a)= P(a<X<=x)/P(X>a)$

$P(a<X<=x)=F(x)-F(a)$

$P(X>a)=1-F(a)$

#4-b)
derivative of above is
f(x)/(1-F(a))

#4-c)
1-F(a) is >0 and f is >0, so its >0
it integrates to 1 because
the the limit of integration is from a to infinity
which gives 1-F(a) which cancels.


#5-a)
$A=\pi R^2$

$E(A)=\pi E(R^2)=\pi(1/3)$

$Var(A)=Var(\pi R^2)=\pi^2 Var(R^2)$

$Var(R^2)=E(R^4)-E^2(R^2)$

$E(R^4)$ is integral from 0 to 1 of $R^4$
which is 1/5

and $E(R^2)^2=(1/3)^2$

so the answer is 1/5-1/9

#5-b)
$P(\pi R^2 \le a)=P(R \le \sqrt{a/\pi})=\sqrt{a/\pi}$

for $0< a< \pi$, because R is Unif(0,1)

for $\pi\le a$ its 1

for $a\le 0$ its 0

Differentiating wrt to a gives the pdf.


#6-a)

For $X \sim Unif(0,1), \mu=1/2, \sigma=\frac{1}{\sqrt(12)}$

So 

$P(\mu-\sigma<X<\mu+\sigma)$ = length of that interval


For 1 std => 2/sqrt(12)

For 2 std => 4/sqrt(12)

For 3 std => 6/sqrt(12)


#6-b)

For $X \sim Expo(1)$ 

$E(X)=1$ 

$\sigma=1$

$P(\mu-\sigma<X<\mu+\sigma)$ 

For 1 std $P(0<X<2)$

plugging in to its cdf, $1-e^{-2}$

For 2 std $P(0<X<3)$ its $1-e^{-3}$

For 3 std $P(0<X<4)$ its $1-e^{-4}$


#6-c)

For $X \sim Expo(1/2)$ 

$E(X)=2$

$\sigma=2$

For 1 std $P(0<X<4)$ its $1-e^{-2}$

For 2 std $P(0<X<6)$ its $1-e^{-3}$

For 3 std $P(0<X<8)$ its $1-e^{-4}$

Same as above, since lambdas cancel.

This is true for any expo.

#7-a)

F is increasing, right cont and converges to 0 and 1 for -infinity, +infinity (ie 0 and 1)

its pdf is 

https://www.wolframalpha.com/input/?i=derivative+(2%2Fpi)*sin%5E-1(sqrt(x))

for 0<x<1

#7-b)
its positive and integrates to 1

#8-a)
https://www.wolframalpha.com/input/?i=integral+12x%5E2(1-x)

for 0<x<1

#8-b)
https://www.wolframalpha.com/input/?i=integral+12x%5E2(1-x)+from+0+to+1%2F2

#8-c)
Mean

https://www.wolframalpha.com/input/?i=integral+12x%5E3(1-x)+from+0+to+1

which is 0.6

E(X^2)
https://www.wolframalpha.com/input/?i=integral+12x%5E4(1-x)+from+0+to+1

which is 0.4
0.4-(0.6)^2=0.04

#9)

1st quadrant in 

https://www.wolframalpha.com/input/?i=integral+1%2F(pi*(1%2Bx%5E2))


#10-a)

1/8 is the pdf

and (2-0)+(7-3)= 2+4=6
answer is 6/8

#10-b)

P(U<=x | U is in (3,7))

is 

P(U<=x,3<U<7)/P(3<U<7)

equals to 

((x-3)/8)/(4/8) = (x-3)/4

#11-a)

$E(U)=1$

$Var(U)=(1--1)^2/12= 4/12=1/3$

$E(U^4)= 1/2\int_{-1}^{1}u^4du = 1/10(1--1)=1/5$


#11-b)

cdf is 

$P(U^2\le x)=P(|U|\le x)=P(-\sqrt x \le U \le \sqrt x)$

$=\int_{-\sqrt x}^{\sqrt x} 1/2 = \sqrt x$

pdf is the derivate of that

$\frac{x^-1/2}{2}$

not uniform



#12

Let stick length be 1

and l be the length of longer piece

then $1/2\le l \le 1$

So $P(l<1/2)=0$ and $P(1\le l)=1$

and whats of interest is the inside of this region.

If its broken at 0<b<1

l = max((1-b),b)

now given a g $1/2\le g \le 1$

we are looking for 

$P(l\le g)$ 

$=P(b\le g \ and \ 1-b\le g$

$=P(1-g \le b\le g)$

$=2g-1$

this is the cdf.

pdf is 2

and $E(l)=\int_{1/2}^{1}2xdx=1-1/4=3/4$

#13-a)

$R=(1-Y)/Y$ and we know the distribution of Y from previous question.

cdf is $P(R\le r)=P((1-Y)/Y\le r)=P(1/(r+1)\le Y)$


$=1-P(Y<1/(r+1))=1-(2(1/(r+1))-1)=2-2/(r+1)$

pdf is the derivative of that

#13-b)

using the pdf and lotus

https://m.wolframalpha.com/input/?i=integral+2x%2F%28x%2B1%29%5E2+from+0+to+1

#13-c)

againg using the pdf and lotus

https://m.wolframalpha.com/input/?i=integral+2%2Fx%28x%2B1%29%5E2+from+0+to+1

it blows up

#14)

$P(X\le x)=P(U_1,U_2,..,U_n\le x)$

since iid

$=\prod P(U_i\le x)=x^n$

pdf is the derivative of that

use lotus to find the E(X)

https://m.wolframalpha.com/input/?i=integral+nx%5En

#15)

$U\sim Unif(0,1)$

If $X\sim Expo(\lambda)$

then 

$F(x)=1-e^{-\lambda x)}$

By universality of the Uniform

$F^{-1} (U) \sim Expo(\lambda)$

$F^{-1}=-log(1-x)/\lambda$

$F^{-1}(U)=-log(1-U)/\lambda \sim Expo(\lambda)$

#16-a)

X is a function of U => f(U)

X^2 is also a function of U => g(U)=f^2(U)

and pdf of U is 1

so using LOTUS

$\int log(U/(1-U))^2 dx$

#16-b)

$E(log(U/(1-U)))=E(log(U)-log(1-U))$

$=E(log(U))-E(log(1-U))=0$

since U and 1-U have the same distribution

#17)

By universality of the Uniform

$X=F^{-1} (U)$ has cdf F

$F^{-1}(x)=(-log(1-y))^{1/3}$

plug in U to that


#18-a)

cdf is $\int_{1}^{z} ax^{-(a+1)} dx$  

its increasing and integrates to 1

$-x^{-a} \rvert_{1}^{\infty}=0--1=1$

#18-b)

the inverse of the cdf is

$(-x)^{-1/a}$

plug U to that


#19)

If $U\sim Unif(0,1)$ then $X=F^{-1}(U)\sim F$

since pdf of Uniform is 1

$\int_{0}^{1}F^{-1}(u)du=E(X)$ 

#20-a)

$\int_{0}^{\infty}P(X>x)dx$

$=\int_{0}^{\infty}(1-P(X\le x))dx$

$=\int_{0}^{\infty}1dx-\int_{0}^{\infty}P(X\le x))dx$

if you draw some cdf and check what this expression corresponds to, you will see that it is the are under the curve of the inverse of F from 0 to 1.

#20-b)

Using the previous result

$E(X)=\int_{0}^{\infty}P(X>t)dt$

$= \int_{0}^{\infty}E(I(X>t))dt$

swapping E and the integral we have 

$E(X)= E\int_{0}^{\infty}I(X>t)dt$

as in the proof of thm 4.4.8 the sum of ind. r.v. is X, here the sum is the integral.

#21)

$Z=(Y-1)/4$

so $4Z+1 \sim N(1,4)$

#22-a)

$erf(z)=\frac{2}{\sqrt\pi} \int_{0}^{z}e^{-x^2}dx$

substitute $x=t/\sqrt{2}$ so that it starts to look like the normal cdf. 

the integration limits and differentials change and we get

$\frac{2}{\sqrt{\pi}} \int_{0}^{z\sqrt{2}}e^{-t^2/2} \frac{1}{\sqrt 2}dt$

$=\frac{2}{\sqrt{2\pi}} \int_{0}^{z\sqrt{2}}e^{-t^2/2} dt$

$=2(\phi(z\sqrt 2)-\phi(0))$

$=2(\phi(z\sqrt 2)-1/2)$

$erf(z)=2\phi(z\sqrt 2)-1$

so

$erf(\frac{z}{\sqrt 2})=2\phi(z)-1$


#22-b)

$erf(z)=2\phi(z\sqrt 2)-1$ this is the area between two limits $z/\sqrt 2$ and $-z/\sqrt 2$

erf(-z) is the negative of that

#23-a)

the second derivative of normal pdf is 

https://m.wolframalpha.com/input/?i=2nd+derivative+e%5E%28-%28x%5E2%29%2F2%29%2Fsqrt%282pi%29

changes sign at -1 and 1

#23-b)

If $X \sim N(\mu,\sigma ^2)$

then $\frac{X-\mu}{\sigma} \sim N(0,1)$

so $\mu+\sigma$ $\mu-\sigma$

#24)

Let X be the observed distance

$X=10+\epsilon$ where $\epsilon \sim N(0,0.04)$

$P(9.6 \le X \le 10.4 )=?$

$=P(9.6 \le 10+\epsilon \le 10.4 )$

$=P(-0.4 \le \epsilon \le 0.4)$

$=\phi(0.4/\sqrt{0.04})-\phi(-0.4/\sqrt{0.04})$

$=\phi(2)-\phi(-2) \approx 0.95$

#25-a)

$P(interpret 1 | sent 1) = P(1/2<received)$
$= P(0.5<1+error)$
$= P(-0.5<error)$
$= 1-\phi(-0.5/\sigma)$


P(interpret 0 | sent 0) = P(received<1/2)
= P(0+error<0.5)
$= \phi(0.5/\sigma)$

So in both cases the probability Bob understands is the same, eg. if 1/2 is the probability of sending 1 or 0 then the overall understanding probability is the same 

$2\phi(0.5/\sigma)1/2= \phi(0.5/\sigma)$

#25-b)

if $\sigma is very small this probability is close to 1, if very large its close to 0.5, ie random, makes sense.

#26)

$T \sim N(0,8)$
$P(T\le 1)-P(T\le 0)$
$=\phi(1/8)-\phi(0)$

#27)

$X-Y \sim N(a-c,b^2+d^2)$

$P(X<Y)=P(X-Y<0)=\phi(\frac{0-(a-c)}{\sqrt{b^2+d^2}})$

$=\phi((c-a)/(b^2+d^2))$

eg:

mean((rnorm(1000,1,3)-rnorm(1000,5,7))<0)=`r mean((rnorm(1000,1,3)-rnorm(1000,5,7))<0)`

pnorm(4/sqrt(9+49))=`r pnorm(4/sqrt(9+49))`

or
pnorm(0,-4,sqrt(9+49))=`r pnorm(0,-4,sqrt(9+49))`

#28-a)

Let X,Y be the times (rvs) Walter and Carl arrives.

$X \sim N(w,\sigma^2)$

$Y \sim N(c,4\sigma^2)$

$Y-X \sim N(c-w,5\sigma^2)$

$P(Y<X)=P(Y-X<0)=\phi(\frac{0-(c-w)}{\sigma\sqrt{5}})$ 

#28-b)

The criterion is 
$\phi(\frac{0-(c-w)}{\sigma\sqrt{5}})>0.5$

ie. w-c>0

#28-c)

P(Carl on time)>P(Walter on time)

$P(Y<w+10)>P(X<w+10)$


$\phi(\frac{w+10-c}{\sigma})> \phi(\frac{w+10-w}{2\sigma})$

ie. 

$\phi(\frac{w+10-c}{\sigma})> \phi(\frac{5}{\sigma})$

ie. 

$w+10-c>5$

ie. 

$w+5>c$

#29)

If you fix (-1,1) and move that interval along the x-axis, the area never increases.

eg.

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
x <- seq(0, 3, length=1000)
y <- pnorm(1+x)-pnorm(x-1)
plot(x, y, type="l", lwd=1)
```


#30)

$(Y-1.96,Y+1.96)$

Here $\mu$ is considered unknown.

#31-a)


Y=|X|

This is called a folded normal distribution.
https://en.wikipedia.org/wiki/Folded_normal_distribution


$cdf(Y)=P(|X|<y)=P(-y\le X\le y)=\Phi(\frac{y-\mu}{\sigma})-\Phi(\frac{-y-\mu}{\sigma})$

#31-b)

$(\phi(\frac{y-\mu}{\sigma})+\phi(\frac{-y-\mu}{\sigma}))\frac{1}{\sigma}$

#31-c)

Its not continuous at 0 because its 0 for x<0.
However this is not a problem to find probabilities.

for x>0 it looks like this

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
y <- seq(0, 20, length=1000)
z<-(dnorm((y-1)/2,mean=1,sd=2)+dnorm((-y-1)/2,mean=1,sd=2))/2
plot(y, z, type="l", lwd=1)
```


#32)

$P(SZ<x)=P(SZ \le x|S=1)P(S=1)+P(-x\le SZ |S=-1)P(S=-1)$

$= P(Z \le x)$ => its N(0,1)

#33)

$\Phi(Z)$ is a symmetric (wrt y=0.5) function
from (-infinity, +infinity) to (0,1)

so 0.5 must be the expectation

Also by universality of uniform $\Phi(Z)\sim Unif(0,1)$
So $E(\Phi(Z))=1/2$

#34-a)

$P(1\le X\le 4)$ corresponds to the region 

X being in (-2,-1) U (1,2)

this is $\phi(2)-\phi(1)+\phi(-1)+\phi(-2)$

so $2(\phi(2)-\phi(1))=(0.95-0.68)$

#34-b)

$E(I(Z\gt t))\le \frac{1}{t}E(ZI(X\gt t))$

$\frac{1}{t}E(ZI(X\gt t))$
$=\frac{1}{t}\int_{\infty}^{\infty}zI(z>t)\phi(z)dz$
$=\frac{1}{t}\int_{t}^{\infty}z\phi(z)dz$

let $u=z^2/2$

then its possible to find the antiderivative of

$z\phi(z)$

$\int z\phi(z)dz=\int ze^{-z^2/2}dz=\int e^{-u}du=-e^{-u}+C=-e^{-x^2/2}+C$

So

$P(Z>t)\le \frac{1}{\sqrt{2\pi}t}\phi(t)$

So 

$P(Z>t)\le \frac{1}{t}\phi(t)$

So 

$1-\frac{1}{t}\phi(t)\le \Phi(t)$

#35-a)

based on pdf o Z

$\int_{-\infty}^{+\infty} z^4 \phi(z) dz$

$=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty} z^4 e^{-z^2/2} dz$

based on pdf o Z^2

$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty} \frac{1}{\sqrt{w}}w^2e^{-w/2}dw$

#35-b)

$E(Z^2)=Var(Z)+E^2(Z)=1$

$E(Z)=0$

$E(\Phi(Z))=1/2$ by univ. of unif

#35-c)

$P(Z^2\le z)=P(-z\le Z\le z)=\Phi(z)-\Phi(-z)$

#36)

$E(ZI_{Z>0})=\int_{-\infty}^{+\infty}zI_{z>0}\phi(z)dz$

$=\int_{0}^{+\infty}z\phi(z)dz=\frac{1}{\sqrt{2\pi}}e^{-z^2/2} \rvert_{0}^{\infty}=\frac{1}{\sqrt{2\pi}}$

$E((ZI_{Z>0})^2)=\int_{0}^{+\infty}z^2\phi(z)dz=\sqrt{2\pi}/2$

its in the book p214

#37) TODO

#38) TODO

#39)

$X,Y,Z \sim Expo(1/6)$

Earliest time when all 3 complete is the max of X,Y,Z

eg:

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
x<- rexp(10000,1/6)
y<- rexp(10000,1/6)
z<- rexp(10000,1/6)
m<- pmax(x,y,z)

par(mfrow=c(2,1))
hist(x)
hist(m)
mean(m)
```

Curious!

To find the cdf:

$P(max(X,Y,Z)\le w)=P(X\le w\land Y\le w\land Z\le w )$
$=P(X\le w)P(Y\le w)P(Z\le w)$
$=(1-e^{-\lambda x})^3$

This will get complicated..

So try another route. We know from the book that minimum of n iid $Expo(\lambda)$s is $Expo(n\lambda)$

$E(max(X,Y,Z))=E(A+B+C)$

where A is the time for the minimum of 3 to happen
B, the minimum of 2 to happen
C, the minimum of 1 to happen

So

$=E(A)+E(B)+E(C)=1/3\lambda+1/2\lambda+1/\lambda$
$=11/6\lambda$

with $\lambda=1/6$ this gives 11 agreeing the simulation above.

By direct calculation

https://m.wolframalpha.com/input/?i=integral+1%2F2x%28e%5E%28-x%2F2%29%29%28e%5E%28x%2F6%29-1%29%5E2+from+0+to+infinity

#40-a)

$P(T<x)=F(x)=0.5$

$x=F^{-1}(0.5)$

$F^{-1}(x)=-\frac{log(1-x)}{\lambda}$

$F^{-1}(0.5)=-\frac{log(0.5)}{\lambda}$

#40-b)

$\frac{F(t+\epsilon)-F(t)}{1-F(t)}$

$=\frac{(1-e^{-\lambda (t+\epsilon)})-(1-e^{-\lambda t})}{1-(1-e^{-\lambda t})}$

$=\frac{e^{-\lambda t}-e^{-\lambda (t+\epsilon)}}{e^{-\lambda t}}$

$=1-e^{-\lambda \epsilon}$

Since for $x\approx 0$ we have
$e^{x}\approx 1+x$

$e^{-x}\approx 1-x$

So

$=1-e^{-\lambda \epsilon}=1-(1-\epsilon)=\epsilon$

#40-c)

$min(T_i)\sim Expo(n\lambda)$ for $T_i\sim Expo(\lambda)$

#40-d) 

Similar to what we did on 39

#41-a)

The probability that an offer is more than 15000 is

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
1-pexp(15000,rate=10^-4)
```

https://m.wolframalpha.com/input/?i=sum+%281%2Bi%29p%281-p%29%5Ei+from+i%3D0+to+infinity%2C+p%3D0.2231302

This is the mean of the First Success distribution with p=

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
1-pexp(15000,rate=10^-4)
```


#41-b)

Conditional pdf is NOT the same as unconditional but shifted because of memorylessness, so if f(t) is the pdf f(t-x) is the conditional pdf

so 15000+10000 is the expected sale price


#42-a)

10

#42-b)

Distribution example:

Consider:

|min|probability|
|---|----|
|1|90/99|
|100|9/99|

here bus to bus mean is 10

But Fred to bus mean is (1/101)+(100/101)100

because Fred 100 times more likely to arrive at a 100 min interarrival  duration then a 1 min one.

#43-a)

TODO

#43-b)

Lets try a simulation

Say,
Route 1 is Pois(7)

Route 2 is Pois(3)

and

n=5

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
results<-replicate(10^4,all(cumsum(rexp(5,7))<rexp(1,3)))

sum(results)/10^4
(7/(7+3))^5
```

By direct calculation, 1-(the result below)

https://m.wolframalpha.com/input/?i=integrate+%28sum+%28%28%287t%29%5Ek%29%28e%5E%28-7t%29%29%29%2Fk%21+from+k%3D0+to+4%29+%283e%5E%28-3t%29%29+dt+from+0+to+infinity

Cool!

#43-c)

max of expos, done before, see 39

#44) 

Done in solutions manual

#45-a)

if G is n, T is $n\Delta t$

#45-b)

If time is t, G is $t/\Delta t$ by a

$P(T>t)=1-(1-\lambda\Delta t)^{t/\Delta t}$

#45-c)

Yep.

https://m.wolframalpha.com/input/?i=limit+%281-%281-ax%29%5E%28t%2Fx%29%29+as+x+goes+to+0


#46-a)

```{r, echo=TRUE, eval=TRUE}
curve(0.5*exp(abs(x)),from=-3, to=3, 1000)
```

```{r, echo=TRUE, eval=TRUE}
curve(exp(-x),from=0, to=3, 1000)
```

#46-b)

$P(SX\le g)=P(SX\le g | S=1)P(S=1)+P(SX\le g | S=-1)P(S=-1)$

$=P(X\le g)0.5+1\cdot0.5$

$=0.5(1+cdf(g))$

so pdf is $0.5\cdot pdf(g)$

same pdf with laplace for x>0

#47)

$P(T>0.1)$ means the probability of the 3rd email arriving after 0.1 hours

means at most 2 emails before that time.

the number of emails N that arrive at or before time t is distributed as Pois(20t)

So P(N=0) or P(N=1) or P(N=2)

sum them

$e^{-2}(2^0+2^1+2^2/2)$

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
exp(-2)*(2^0+2^1+(2^2)/2)
```

or

```{r, echo=TRUE, eval=TRUE, cache=TRUE}
ppois(2,2)
```

#48)
